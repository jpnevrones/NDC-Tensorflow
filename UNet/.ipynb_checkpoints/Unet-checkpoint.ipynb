{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "tcurrent   = start_time\n",
    "\n",
    "# Set golbal parameters\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNELS = 3\n",
    "TRAIN_PATH = 'input/stage1_train/'\n",
    "TEST_PATH = 'input/stage1_test/'\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
    "seed = 545 # original seed: 42\n",
    "random.seed = seed\n",
    "np.random.seed = seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test IDs\n",
    "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
    "test_ids = next(os.walk(TEST_PATH))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing train images and masks ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 670/670 [01:59<00:00,  5.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing test images ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 50.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Get and resize train images and masks\n",
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "print('Getting and resizing train images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    path = TRAIN_PATH + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_train[n] = img\n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "        mask_ = imread(path + '/masks/' + mask_file)\n",
    "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n",
    "                                      preserve_range=True), axis=-1)\n",
    "        mask = np.maximum(mask, mask_)\n",
    "    Y_train[n] = mask\n",
    "\n",
    "# Get and resize test images\n",
    "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "sizes_test = []\n",
    "print('Getting and resizing test images ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = TEST_PATH + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_test[n] = img\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASEAAAEYCAYAAAATaEB+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH4QcxxmU/w/zNznurSfMaAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d178d625f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASEAAAEYCAYAAAATaEB+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqSlDSFJThpCkpgwhSU39H7B1D8JghDw8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d1754b77b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check if training data looks all right\n",
    "ix = random.randint(0, len(train_ids))\n",
    "imshow(X_train[ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[ix]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define IoU metric\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 128, 128, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 8)  224         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 8)  584         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 8)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 16)   1168        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 16)   2320        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 16)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 32)   4640        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 32)   9248        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 32)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 64)   18496       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 64)   36928       conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 64)     0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 8, 8, 128)    73856       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 8, 128)    147584      conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 16, 16, 64)   32832       conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16, 16, 128)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 64)   73792       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 64)   36928       conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 32, 32, 32)   8224        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 64)   0           conv2d_transpose_2[0][0]         \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 32)   18464       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 32)   9248        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 64, 64, 16)   2064        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 64, 64, 32)   0           conv2d_transpose_3[0][0]         \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 16)   4624        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 16)   2320        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 128, 128, 8)  520         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 128, 128, 16) 0           conv2d_transpose_4[0][0]         \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 8)  1160        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 128, 128, 8)  584         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 128, 128, 1)  9           conv2d_18[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 485,817\n",
      "Trainable params: 485,817\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build U-Net model\n",
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "s = Lambda(lambda x: x / 255) (inputs)\n",
    "\n",
    "c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (s)\n",
    "c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\n",
    "p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\n",
    "c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\n",
    "p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\n",
    "c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\n",
    "p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\n",
    "c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\n",
    "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (p4)\n",
    "c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (c5)\n",
    "p5 = MaxPooling2D(pool_size=(2, 2)) (c5)\n",
    "\n",
    "c = Conv2D(256, (3, 3), activation='relu', padding='same') (p5)\n",
    "c = Conv2D(256, (3, 3), activation='relu', padding='same') (c)\n",
    "\n",
    "u61 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c)\n",
    "u61 = concatenate([u61, c5])\n",
    "c61 = Conv2D(128, (3, 3), activation='relu', padding='same') (u61)\n",
    "c61 = Conv2D(128, (3, 3), activation='relu', padding='same') (c61)\n",
    "\n",
    "u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "u6 = concatenate([u6, c4])\n",
    "c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\n",
    "c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n",
    "\n",
    "u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "u7 = concatenate([u7, c3])\n",
    "c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\n",
    "c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n",
    "\n",
    "u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "u8 = concatenate([u8, c2])\n",
    "c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\n",
    "c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n",
    "\n",
    "u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "u9 = concatenate([u9, c1], axis=3)\n",
    "c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\n",
    "c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 603 samples, validate on 67 samples\n",
      "Epoch 1/100\n",
      "600/603 [============================>.] - ETA: 2:15 - loss: 0.6891 - mean_iou: 0.0000e+ - ETA: 1:27 - loss: 0.6848 - mean_iou: 0.1987   - ETA: 1:11 - loss: 0.6811 - mean_iou: 0.27 - ETA: 1:02 - loss: 0.6760 - mean_iou: 0.30 - ETA: 57s - loss: 0.6720 - mean_iou: 0.3261 - ETA: 53s - loss: 0.6675 - mean_iou: 0.340 - ETA: 50s - loss: 0.6611 - mean_iou: 0.352 - ETA: 48s - loss: 0.6570 - mean_iou: 0.361 - ETA: 46s - loss: 0.6543 - mean_iou: 0.368 - ETA: 45s - loss: 0.6494 - mean_iou: 0.373 - ETA: 43s - loss: 0.6423 - mean_iou: 0.377 - ETA: 42s - loss: 0.6414 - mean_iou: 0.380 - ETA: 41s - loss: 0.6373 - mean_iou: 0.382 - ETA: 40s - loss: 0.6356 - mean_iou: 0.385 - ETA: 39s - loss: 0.6323 - mean_iou: 0.387 - ETA: 38s - loss: 0.6243 - mean_iou: 0.388 - ETA: 37s - loss: 0.6214 - mean_iou: 0.390 - ETA: 36s - loss: 0.6099 - mean_iou: 0.391 - ETA: 35s - loss: 0.6081 - mean_iou: 0.393 - ETA: 34s - loss: 0.6061 - mean_iou: 0.394 - ETA: 33s - loss: 0.6043 - mean_iou: 0.395 - ETA: 32s - loss: 0.6054 - mean_iou: 0.396 - ETA: 32s - loss: 0.6030 - mean_iou: 0.397 - ETA: 31s - loss: 0.5976 - mean_iou: 0.397 - ETA: 30s - loss: 0.5941 - mean_iou: 0.398 - ETA: 30s - loss: 0.5892 - mean_iou: 0.399 - ETA: 29s - loss: 0.5847 - mean_iou: 0.399 - ETA: 28s - loss: 0.5841 - mean_iou: 0.400 - ETA: 27s - loss: 0.5770 - mean_iou: 0.400 - ETA: 27s - loss: 0.5728 - mean_iou: 0.401 - ETA: 26s - loss: 0.5730 - mean_iou: 0.401 - ETA: 25s - loss: 0.5676 - mean_iou: 0.402 - ETA: 25s - loss: 0.5622 - mean_iou: 0.402 - ETA: 24s - loss: 0.5581 - mean_iou: 0.403 - ETA: 23s - loss: 0.5519 - mean_iou: 0.403 - ETA: 23s - loss: 0.5512 - mean_iou: 0.403 - ETA: 22s - loss: 0.5434 - mean_iou: 0.404 - ETA: 22s - loss: 0.5423 - mean_iou: 0.404 - ETA: 21s - loss: 0.5344 - mean_iou: 0.404 - ETA: 20s - loss: 0.5336 - mean_iou: 0.405 - ETA: 20s - loss: 0.5303 - mean_iou: 0.405 - ETA: 19s - loss: 0.5287 - mean_iou: 0.406 - ETA: 19s - loss: 0.5256 - mean_iou: 0.406 - ETA: 18s - loss: 0.5225 - mean_iou: 0.406 - ETA: 17s - loss: 0.5213 - mean_iou: 0.407 - ETA: 17s - loss: 0.5185 - mean_iou: 0.407 - ETA: 16s - loss: 0.5156 - mean_iou: 0.407 - ETA: 15s - loss: 0.5156 - mean_iou: 0.407 - ETA: 15s - loss: 0.5133 - mean_iou: 0.408 - ETA: 14s - loss: 0.5101 - mean_iou: 0.408 - ETA: 14s - loss: 0.5098 - mean_iou: 0.408 - ETA: 13s - loss: 0.5062 - mean_iou: 0.408 - ETA: 12s - loss: 0.5025 - mean_iou: 0.409 - ETA: 12s - loss: 0.5001 - mean_iou: 0.409 - ETA: 11s - loss: 0.4966 - mean_iou: 0.409 - ETA: 11s - loss: 0.4932 - mean_iou: 0.409 - ETA: 10s - loss: 0.4905 - mean_iou: 0.409 - ETA: 10s - loss: 0.4886 - mean_iou: 0.410 - ETA: 9s - loss: 0.4861 - mean_iou: 0.410 - ETA: 8s - loss: 0.4841 - mean_iou: 0.41 - ETA: 8s - loss: 0.4818 - mean_iou: 0.41 - ETA: 7s - loss: 0.4786 - mean_iou: 0.41 - ETA: 7s - loss: 0.4751 - mean_iou: 0.41 - ETA: 6s - loss: 0.4717 - mean_iou: 0.41 - ETA: 5s - loss: 0.4707 - mean_iou: 0.41 - ETA: 5s - loss: 0.4688 - mean_iou: 0.41 - ETA: 4s - loss: 0.4685 - mean_iou: 0.41 - ETA: 4s - loss: 0.4663 - mean_iou: 0.41 - ETA: 3s - loss: 0.4643 - mean_iou: 0.41 - ETA: 3s - loss: 0.4619 - mean_iou: 0.41 - ETA: 2s - loss: 0.4588 - mean_iou: 0.41 - ETA: 1s - loss: 0.4577 - mean_iou: 0.41 - ETA: 1s - loss: 0.4564 - mean_iou: 0.41 - ETA: 0s - loss: 0.4548 - mean_iou: 0.41 - ETA: 0s - loss: 0.4538 - mean_iou: 0.4131\n",
      "Epoch 00001: val_loss improved from inf to 0.34105, saving model to model-dsbowl2018-1.h5\n",
      "603/603 [==============================] - 47s 77ms/step - loss: 0.4527 - mean_iou: 0.4131 - val_loss: 0.3411 - val_mean_iou: 0.4232\n",
      "Epoch 2/100\n",
      "600/603 [============================>.] - ETA: 42s - loss: 0.3126 - mean_iou: 0.423 - ETA: 48s - loss: 0.3348 - mean_iou: 0.423 - ETA: 45s - loss: 0.3505 - mean_iou: 0.423 - ETA: 44s - loss: 0.3581 - mean_iou: 0.423 - ETA: 42s - loss: 0.3497 - mean_iou: 0.423 - ETA: 41s - loss: 0.3631 - mean_iou: 0.423 - ETA: 42s - loss: 0.3586 - mean_iou: 0.423 - ETA: 41s - loss: 0.3521 - mean_iou: 0.423 - ETA: 40s - loss: 0.3349 - mean_iou: 0.423 - ETA: 39s - loss: 0.3310 - mean_iou: 0.423 - ETA: 38s - loss: 0.3235 - mean_iou: 0.423 - ETA: 39s - loss: 0.3174 - mean_iou: 0.423 - ETA: 38s - loss: 0.3144 - mean_iou: 0.423 - ETA: 38s - loss: 0.3087 - mean_iou: 0.423 - ETA: 37s - loss: 0.3006 - mean_iou: 0.423 - ETA: 37s - loss: 0.2963 - mean_iou: 0.423 - ETA: 37s - loss: 0.2948 - mean_iou: 0.423 - ETA: 36s - loss: 0.2937 - mean_iou: 0.423 - ETA: 35s - loss: 0.2954 - mean_iou: 0.423 - ETA: 35s - loss: 0.2980 - mean_iou: 0.423 - ETA: 34s - loss: 0.2969 - mean_iou: 0.423 - ETA: 33s - loss: 0.2948 - mean_iou: 0.423 - ETA: 33s - loss: 0.2918 - mean_iou: 0.423 - ETA: 32s - loss: 0.2880 - mean_iou: 0.423 - ETA: 31s - loss: 0.2857 - mean_iou: 0.423 - ETA: 30s - loss: 0.2825 - mean_iou: 0.423 - ETA: 30s - loss: 0.2829 - mean_iou: 0.423 - ETA: 29s - loss: 0.2846 - mean_iou: 0.423 - ETA: 28s - loss: 0.2827 - mean_iou: 0.423 - ETA: 28s - loss: 0.2812 - mean_iou: 0.423 - ETA: 27s - loss: 0.2810 - mean_iou: 0.423 - ETA: 26s - loss: 0.2803 - mean_iou: 0.423 - ETA: 26s - loss: 0.2796 - mean_iou: 0.423 - ETA: 25s - loss: 0.2793 - mean_iou: 0.423 - ETA: 25s - loss: 0.2790 - mean_iou: 0.423 - ETA: 24s - loss: 0.2797 - mean_iou: 0.423 - ETA: 23s - loss: 0.2797 - mean_iou: 0.423 - ETA: 23s - loss: 0.2794 - mean_iou: 0.423 - ETA: 22s - loss: 0.2795 - mean_iou: 0.423 - ETA: 21s - loss: 0.2795 - mean_iou: 0.423 - ETA: 21s - loss: 0.2808 - mean_iou: 0.423 - ETA: 20s - loss: 0.2794 - mean_iou: 0.423 - ETA: 19s - loss: 0.2801 - mean_iou: 0.423 - ETA: 19s - loss: 0.2798 - mean_iou: 0.423 - ETA: 18s - loss: 0.2765 - mean_iou: 0.423 - ETA: 17s - loss: 0.2747 - mean_iou: 0.423 - ETA: 17s - loss: 0.2749 - mean_iou: 0.423 - ETA: 16s - loss: 0.2741 - mean_iou: 0.423 - ETA: 16s - loss: 0.2712 - mean_iou: 0.423 - ETA: 15s - loss: 0.2697 - mean_iou: 0.423 - ETA: 14s - loss: 0.2679 - mean_iou: 0.423 - ETA: 14s - loss: 0.2671 - mean_iou: 0.423 - ETA: 13s - loss: 0.2648 - mean_iou: 0.423 - ETA: 12s - loss: 0.2625 - mean_iou: 0.423 - ETA: 12s - loss: 0.2601 - mean_iou: 0.423 - ETA: 11s - loss: 0.2610 - mean_iou: 0.423 - ETA: 11s - loss: 0.2600 - mean_iou: 0.423 - ETA: 10s - loss: 0.2596 - mean_iou: 0.423 - ETA: 9s - loss: 0.2602 - mean_iou: 0.423 - ETA: 9s - loss: 0.2593 - mean_iou: 0.42 - ETA: 8s - loss: 0.2579 - mean_iou: 0.42 - ETA: 8s - loss: 0.2576 - mean_iou: 0.42 - ETA: 7s - loss: 0.2552 - mean_iou: 0.42 - ETA: 6s - loss: 0.2541 - mean_iou: 0.42 - ETA: 6s - loss: 0.2518 - mean_iou: 0.42 - ETA: 5s - loss: 0.2513 - mean_iou: 0.42 - ETA: 4s - loss: 0.2500 - mean_iou: 0.42 - ETA: 4s - loss: 0.2502 - mean_iou: 0.42 - ETA: 3s - loss: 0.2502 - mean_iou: 0.42 - ETA: 3s - loss: 0.2507 - mean_iou: 0.42 - ETA: 2s - loss: 0.2499 - mean_iou: 0.42 - ETA: 1s - loss: 0.2497 - mean_iou: 0.42 - ETA: 1s - loss: 0.2500 - mean_iou: 0.42 - ETA: 0s - loss: 0.2494 - mean_iou: 0.42 - ETA: 0s - loss: 0.2488 - mean_iou: 0.4237\n",
      "Epoch 00002: val_loss improved from 0.34105 to 0.18161, saving model to model-dsbowl2018-1.h5\n",
      "603/603 [==============================] - 47s 78ms/step - loss: 0.2479 - mean_iou: 0.4238 - val_loss: 0.1816 - val_mean_iou: 0.4278\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/603 [============================>.] - ETA: 45s - loss: 0.1499 - mean_iou: 0.429 - ETA: 46s - loss: 0.1878 - mean_iou: 0.429 - ETA: 44s - loss: 0.1815 - mean_iou: 0.429 - ETA: 44s - loss: 0.1833 - mean_iou: 0.429 - ETA: 42s - loss: 0.1811 - mean_iou: 0.429 - ETA: 42s - loss: 0.1817 - mean_iou: 0.429 - ETA: 41s - loss: 0.1936 - mean_iou: 0.430 - ETA: 40s - loss: 0.2007 - mean_iou: 0.430 - ETA: 39s - loss: 0.2066 - mean_iou: 0.430 - ETA: 39s - loss: 0.2131 - mean_iou: 0.430 - ETA: 38s - loss: 0.2146 - mean_iou: 0.430 - ETA: 37s - loss: 0.2159 - mean_iou: 0.430 - ETA: 36s - loss: 0.2133 - mean_iou: 0.431 - ETA: 36s - loss: 0.2069 - mean_iou: 0.431 - ETA: 35s - loss: 0.2056 - mean_iou: 0.431 - ETA: 35s - loss: 0.1983 - mean_iou: 0.431 - ETA: 34s - loss: 0.1910 - mean_iou: 0.431 - ETA: 34s - loss: 0.1871 - mean_iou: 0.432 - ETA: 33s - loss: 0.1844 - mean_iou: 0.432 - ETA: 32s - loss: 0.1852 - mean_iou: 0.432 - ETA: 32s - loss: 0.1838 - mean_iou: 0.433 - ETA: 32s - loss: 0.1826 - mean_iou: 0.433 - ETA: 31s - loss: 0.1835 - mean_iou: 0.433 - ETA: 30s - loss: 0.1824 - mean_iou: 0.433 - ETA: 30s - loss: 0.1805 - mean_iou: 0.434 - ETA: 29s - loss: 0.1812 - mean_iou: 0.434 - ETA: 29s - loss: 0.1803 - mean_iou: 0.434 - ETA: 28s - loss: 0.1799 - mean_iou: 0.435 - ETA: 27s - loss: 0.1777 - mean_iou: 0.435 - ETA: 27s - loss: 0.1794 - mean_iou: 0.435 - ETA: 26s - loss: 0.1771 - mean_iou: 0.436 - ETA: 26s - loss: 0.1762 - mean_iou: 0.436 - ETA: 25s - loss: 0.1742 - mean_iou: 0.437 - ETA: 24s - loss: 0.1720 - mean_iou: 0.437 - ETA: 24s - loss: 0.1713 - mean_iou: 0.438 - ETA: 23s - loss: 0.1694 - mean_iou: 0.438 - ETA: 23s - loss: 0.1687 - mean_iou: 0.439 - ETA: 22s - loss: 0.1684 - mean_iou: 0.439 - ETA: 21s - loss: 0.1685 - mean_iou: 0.440 - ETA: 21s - loss: 0.1682 - mean_iou: 0.440 - ETA: 20s - loss: 0.1722 - mean_iou: 0.441 - ETA: 19s - loss: 0.1715 - mean_iou: 0.441 - ETA: 19s - loss: 0.1723 - mean_iou: 0.442 - ETA: 18s - loss: 0.1708 - mean_iou: 0.442 - ETA: 18s - loss: 0.1706 - mean_iou: 0.443 - ETA: 17s - loss: 0.1695 - mean_iou: 0.443 - ETA: 16s - loss: 0.1688 - mean_iou: 0.444 - ETA: 16s - loss: 0.1683 - mean_iou: 0.444 - ETA: 15s - loss: 0.1668 - mean_iou: 0.445 - ETA: 14s - loss: 0.1653 - mean_iou: 0.445 - ETA: 14s - loss: 0.1638 - mean_iou: 0.446 - ETA: 13s - loss: 0.1638 - mean_iou: 0.446 - ETA: 13s - loss: 0.1637 - mean_iou: 0.447 - ETA: 12s - loss: 0.1645 - mean_iou: 0.447 - ETA: 12s - loss: 0.1636 - mean_iou: 0.448 - ETA: 11s - loss: 0.1630 - mean_iou: 0.448 - ETA: 10s - loss: 0.1625 - mean_iou: 0.449 - ETA: 10s - loss: 0.1636 - mean_iou: 0.449 - ETA: 9s - loss: 0.1625 - mean_iou: 0.450 - ETA: 9s - loss: 0.1610 - mean_iou: 0.45 - ETA: 8s - loss: 0.1596 - mean_iou: 0.45 - ETA: 7s - loss: 0.1600 - mean_iou: 0.45 - ETA: 7s - loss: 0.1596 - mean_iou: 0.45 - ETA: 6s - loss: 0.1591 - mean_iou: 0.45 - ETA: 6s - loss: 0.1590 - mean_iou: 0.45 - ETA: 5s - loss: 0.1588 - mean_iou: 0.45 - ETA: 4s - loss: 0.1582 - mean_iou: 0.45 - ETA: 4s - loss: 0.1576 - mean_iou: 0.45 - ETA: 3s - loss: 0.1572 - mean_iou: 0.45 - ETA: 3s - loss: 0.1564 - mean_iou: 0.45 - ETA: 2s - loss: 0.1557 - mean_iou: 0.45 - ETA: 2s - loss: 0.1558 - mean_iou: 0.45 - ETA: 1s - loss: 0.1549 - mean_iou: 0.45 - ETA: 0s - loss: 0.1541 - mean_iou: 0.45 - ETA: 0s - loss: 0.1535 - mean_iou: 0.4586\n",
      "Epoch 00003: val_loss improved from 0.18161 to 0.12229, saving model to model-dsbowl2018-1.h5\n",
      "603/603 [==============================] - 48s 79ms/step - loss: 0.1535 - mean_iou: 0.4588 - val_loss: 0.1223 - val_mean_iou: 0.5022\n",
      "Epoch 4/100\n",
      "600/603 [============================>.] - ETA: 39s - loss: 0.1632 - mean_iou: 0.506 - ETA: 39s - loss: 0.1468 - mean_iou: 0.507 - ETA: 39s - loss: 0.1525 - mean_iou: 0.507 - ETA: 39s - loss: 0.1330 - mean_iou: 0.508 - ETA: 39s - loss: 0.1287 - mean_iou: 0.508 - ETA: 38s - loss: 0.1257 - mean_iou: 0.509 - ETA: 38s - loss: 0.1240 - mean_iou: 0.509 - ETA: 37s - loss: 0.1281 - mean_iou: 0.510 - ETA: 37s - loss: 0.1293 - mean_iou: 0.510 - ETA: 36s - loss: 0.1240 - mean_iou: 0.511 - ETA: 35s - loss: 0.1198 - mean_iou: 0.511 - ETA: 35s - loss: 0.1184 - mean_iou: 0.512 - ETA: 34s - loss: 0.1210 - mean_iou: 0.512 - ETA: 34s - loss: 0.1174 - mean_iou: 0.513 - ETA: 34s - loss: 0.1192 - mean_iou: 0.513 - ETA: 33s - loss: 0.1199 - mean_iou: 0.513 - ETA: 33s - loss: 0.1167 - mean_iou: 0.514 - ETA: 32s - loss: 0.1178 - mean_iou: 0.514 - ETA: 32s - loss: 0.1158 - mean_iou: 0.515 - ETA: 31s - loss: 0.1154 - mean_iou: 0.515 - ETA: 31s - loss: 0.1161 - mean_iou: 0.516 - ETA: 30s - loss: 0.1158 - mean_iou: 0.516 - ETA: 30s - loss: 0.1146 - mean_iou: 0.517 - ETA: 29s - loss: 0.1133 - mean_iou: 0.517 - ETA: 29s - loss: 0.1161 - mean_iou: 0.518 - ETA: 28s - loss: 0.1152 - mean_iou: 0.518 - ETA: 28s - loss: 0.1136 - mean_iou: 0.519 - ETA: 27s - loss: 0.1144 - mean_iou: 0.519 - ETA: 27s - loss: 0.1148 - mean_iou: 0.520 - ETA: 26s - loss: 0.1139 - mean_iou: 0.520 - ETA: 25s - loss: 0.1158 - mean_iou: 0.521 - ETA: 25s - loss: 0.1149 - mean_iou: 0.521 - ETA: 24s - loss: 0.1198 - mean_iou: 0.521 - ETA: 24s - loss: 0.1191 - mean_iou: 0.522 - ETA: 23s - loss: 0.1190 - mean_iou: 0.522 - ETA: 23s - loss: 0.1193 - mean_iou: 0.523 - ETA: 22s - loss: 0.1199 - mean_iou: 0.523 - ETA: 22s - loss: 0.1196 - mean_iou: 0.524 - ETA: 21s - loss: 0.1219 - mean_iou: 0.524 - ETA: 20s - loss: 0.1210 - mean_iou: 0.524 - ETA: 20s - loss: 0.1203 - mean_iou: 0.525 - ETA: 19s - loss: 0.1203 - mean_iou: 0.525 - ETA: 19s - loss: 0.1218 - mean_iou: 0.526 - ETA: 18s - loss: 0.1205 - mean_iou: 0.526 - ETA: 18s - loss: 0.1212 - mean_iou: 0.527 - ETA: 17s - loss: 0.1215 - mean_iou: 0.527 - ETA: 16s - loss: 0.1222 - mean_iou: 0.527 - ETA: 16s - loss: 0.1229 - mean_iou: 0.528 - ETA: 15s - loss: 0.1221 - mean_iou: 0.528 - ETA: 15s - loss: 0.1220 - mean_iou: 0.529 - ETA: 14s - loss: 0.1222 - mean_iou: 0.529 - ETA: 14s - loss: 0.1212 - mean_iou: 0.529 - ETA: 13s - loss: 0.1213 - mean_iou: 0.530 - ETA: 12s - loss: 0.1211 - mean_iou: 0.530 - ETA: 12s - loss: 0.1209 - mean_iou: 0.531 - ETA: 11s - loss: 0.1204 - mean_iou: 0.531 - ETA: 11s - loss: 0.1212 - mean_iou: 0.532 - ETA: 10s - loss: 0.1209 - mean_iou: 0.532 - ETA: 9s - loss: 0.1202 - mean_iou: 0.532 - ETA: 9s - loss: 0.1200 - mean_iou: 0.53 - ETA: 8s - loss: 0.1192 - mean_iou: 0.53 - ETA: 8s - loss: 0.1192 - mean_iou: 0.53 - ETA: 7s - loss: 0.1195 - mean_iou: 0.53 - ETA: 7s - loss: 0.1191 - mean_iou: 0.53 - ETA: 6s - loss: 0.1187 - mean_iou: 0.53 - ETA: 5s - loss: 0.1185 - mean_iou: 0.53 - ETA: 5s - loss: 0.1182 - mean_iou: 0.53 - ETA: 4s - loss: 0.1175 - mean_iou: 0.53 - ETA: 4s - loss: 0.1172 - mean_iou: 0.53 - ETA: 3s - loss: 0.1178 - mean_iou: 0.53 - ETA: 2s - loss: 0.1180 - mean_iou: 0.53 - ETA: 2s - loss: 0.1184 - mean_iou: 0.53 - ETA: 1s - loss: 0.1188 - mean_iou: 0.53 - ETA: 0s - loss: 0.1181 - mean_iou: 0.53 - ETA: 0s - loss: 0.1181 - mean_iou: 0.5392\n",
      "Epoch 00004: val_loss improved from 0.12229 to 0.11425, saving model to model-dsbowl2018-1.h5\n",
      "603/603 [==============================] - 50s 84ms/step - loss: 0.1183 - mean_iou: 0.5393 - val_loss: 0.1143 - val_mean_iou: 0.5710\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/603 [============================>.] - ETA: 43s - loss: 0.1361 - mean_iou: 0.573 - ETA: 45s - loss: 0.1550 - mean_iou: 0.574 - ETA: 47s - loss: 0.1316 - mean_iou: 0.574 - ETA: 45s - loss: 0.1422 - mean_iou: 0.574 - ETA: 43s - loss: 0.1562 - mean_iou: 0.575 - ETA: 42s - loss: 0.1438 - mean_iou: 0.575 - ETA: 41s - loss: 0.1387 - mean_iou: 0.575 - ETA: 41s - loss: 0.1354 - mean_iou: 0.576 - ETA: 40s - loss: 0.1322 - mean_iou: 0.576 - ETA: 39s - loss: 0.1267 - mean_iou: 0.576 - ETA: 38s - loss: 0.1208 - mean_iou: 0.576 - ETA: 37s - loss: 0.1204 - mean_iou: 0.577 - ETA: 37s - loss: 0.1225 - mean_iou: 0.577 - ETA: 36s - loss: 0.1218 - mean_iou: 0.577 - ETA: 36s - loss: 0.1212 - mean_iou: 0.577 - ETA: 35s - loss: 0.1245 - mean_iou: 0.578 - ETA: 35s - loss: 0.1260 - mean_iou: 0.578 - ETA: 34s - loss: 0.1277 - mean_iou: 0.578 - ETA: 34s - loss: 0.1252 - mean_iou: 0.578 - ETA: 33s - loss: 0.1270 - mean_iou: 0.579 - ETA: 32s - loss: 0.1264 - mean_iou: 0.579 - ETA: 32s - loss: 0.1279 - mean_iou: 0.579 - ETA: 31s - loss: 0.1291 - mean_iou: 0.579 - ETA: 30s - loss: 0.1291 - mean_iou: 0.580 - ETA: 29s - loss: 0.1272 - mean_iou: 0.580 - ETA: 29s - loss: 0.1283 - mean_iou: 0.580 - ETA: 28s - loss: 0.1291 - mean_iou: 0.581 - ETA: 27s - loss: 0.1315 - mean_iou: 0.581 - ETA: 27s - loss: 0.1302 - mean_iou: 0.581 - ETA: 26s - loss: 0.1289 - mean_iou: 0.581 - ETA: 25s - loss: 0.1321 - mean_iou: 0.582 - ETA: 25s - loss: 0.1310 - mean_iou: 0.582 - ETA: 24s - loss: 0.1308 - mean_iou: 0.582 - ETA: 23s - loss: 0.1325 - mean_iou: 0.582 - ETA: 23s - loss: 0.1318 - mean_iou: 0.583 - ETA: 22s - loss: 0.1310 - mean_iou: 0.583 - ETA: 22s - loss: 0.1300 - mean_iou: 0.583 - ETA: 21s - loss: 0.1276 - mean_iou: 0.583 - ETA: 20s - loss: 0.1290 - mean_iou: 0.583 - ETA: 20s - loss: 0.1286 - mean_iou: 0.584 - ETA: 19s - loss: 0.1302 - mean_iou: 0.584 - ETA: 19s - loss: 0.1316 - mean_iou: 0.584 - ETA: 18s - loss: 0.1300 - mean_iou: 0.584 - ETA: 18s - loss: 0.1298 - mean_iou: 0.585 - ETA: 17s - loss: 0.1311 - mean_iou: 0.585 - ETA: 17s - loss: 0.1299 - mean_iou: 0.585 - ETA: 16s - loss: 0.1297 - mean_iou: 0.585 - ETA: 16s - loss: 0.1296 - mean_iou: 0.585 - ETA: 15s - loss: 0.1305 - mean_iou: 0.586 - ETA: 14s - loss: 0.1303 - mean_iou: 0.586 - ETA: 14s - loss: 0.1291 - mean_iou: 0.586 - ETA: 13s - loss: 0.1301 - mean_iou: 0.586 - ETA: 13s - loss: 0.1291 - mean_iou: 0.586 - ETA: 12s - loss: 0.1286 - mean_iou: 0.587 - ETA: 12s - loss: 0.1291 - mean_iou: 0.587 - ETA: 11s - loss: 0.1289 - mean_iou: 0.587 - ETA: 10s - loss: 0.1282 - mean_iou: 0.587 - ETA: 10s - loss: 0.1275 - mean_iou: 0.588 - ETA: 9s - loss: 0.1277 - mean_iou: 0.588 - ETA: 9s - loss: 0.1277 - mean_iou: 0.58 - ETA: 8s - loss: 0.1278 - mean_iou: 0.58 - ETA: 7s - loss: 0.1280 - mean_iou: 0.58 - ETA: 7s - loss: 0.1274 - mean_iou: 0.58 - ETA: 6s - loss: 0.1286 - mean_iou: 0.58 - ETA: 6s - loss: 0.1292 - mean_iou: 0.58 - ETA: 5s - loss: 0.1295 - mean_iou: 0.58 - ETA: 5s - loss: 0.1301 - mean_iou: 0.59 - ETA: 4s - loss: 0.1296 - mean_iou: 0.59 - ETA: 3s - loss: 0.1296 - mean_iou: 0.59 - ETA: 3s - loss: 0.1295 - mean_iou: 0.59 - ETA: 2s - loss: 0.1295 - mean_iou: 0.59 - ETA: 2s - loss: 0.1302 - mean_iou: 0.59 - ETA: 1s - loss: 0.1300 - mean_iou: 0.59 - ETA: 0s - loss: 0.1292 - mean_iou: 0.59 - ETA: 0s - loss: 0.1287 - mean_iou: 0.5918\n",
      "Epoch 00005: val_loss did not improve\n",
      "603/603 [==============================] - 49s 81ms/step - loss: 0.1285 - mean_iou: 0.5919 - val_loss: 0.1143 - val_mean_iou: 0.6105\n",
      "Epoch 6/100\n",
      "600/603 [============================>.] - ETA: 59s - loss: 0.0782 - mean_iou: 0.612 - ETA: 59s - loss: 0.0993 - mean_iou: 0.612 - ETA: 57s - loss: 0.1214 - mean_iou: 0.613 - ETA: 56s - loss: 0.1100 - mean_iou: 0.613 - ETA: 54s - loss: 0.0996 - mean_iou: 0.613 - ETA: 51s - loss: 0.0974 - mean_iou: 0.613 - ETA: 48s - loss: 0.0948 - mean_iou: 0.613 - ETA: 46s - loss: 0.0965 - mean_iou: 0.614 - ETA: 45s - loss: 0.0983 - mean_iou: 0.614 - ETA: 44s - loss: 0.0940 - mean_iou: 0.614 - ETA: 44s - loss: 0.0982 - mean_iou: 0.614 - ETA: 43s - loss: 0.1036 - mean_iou: 0.614 - ETA: 42s - loss: 0.1065 - mean_iou: 0.615 - ETA: 42s - loss: 0.1079 - mean_iou: 0.615 - ETA: 41s - loss: 0.1106 - mean_iou: 0.615 - ETA: 39s - loss: 0.1131 - mean_iou: 0.615 - ETA: 39s - loss: 0.1195 - mean_iou: 0.615 - ETA: 38s - loss: 0.1189 - mean_iou: 0.616 - ETA: 38s - loss: 0.1202 - mean_iou: 0.616 - ETA: 38s - loss: 0.1220 - mean_iou: 0.616 - ETA: 37s - loss: 0.1223 - mean_iou: 0.616 - ETA: 36s - loss: 0.1206 - mean_iou: 0.617 - ETA: 35s - loss: 0.1233 - mean_iou: 0.617 - ETA: 34s - loss: 0.1217 - mean_iou: 0.617 - ETA: 33s - loss: 0.1212 - mean_iou: 0.617 - ETA: 32s - loss: 0.1205 - mean_iou: 0.617 - ETA: 31s - loss: 0.1187 - mean_iou: 0.617 - ETA: 31s - loss: 0.1182 - mean_iou: 0.618 - ETA: 30s - loss: 0.1177 - mean_iou: 0.618 - ETA: 30s - loss: 0.1176 - mean_iou: 0.618 - ETA: 29s - loss: 0.1170 - mean_iou: 0.618 - ETA: 29s - loss: 0.1156 - mean_iou: 0.618 - ETA: 28s - loss: 0.1150 - mean_iou: 0.619 - ETA: 27s - loss: 0.1171 - mean_iou: 0.619 - ETA: 26s - loss: 0.1165 - mean_iou: 0.619 - ETA: 26s - loss: 0.1160 - mean_iou: 0.619 - ETA: 25s - loss: 0.1143 - mean_iou: 0.619 - ETA: 25s - loss: 0.1156 - mean_iou: 0.619 - ETA: 24s - loss: 0.1147 - mean_iou: 0.620 - ETA: 24s - loss: 0.1154 - mean_iou: 0.620 - ETA: 23s - loss: 0.1160 - mean_iou: 0.620 - ETA: 22s - loss: 0.1151 - mean_iou: 0.620 - ETA: 22s - loss: 0.1144 - mean_iou: 0.620 - ETA: 21s - loss: 0.1132 - mean_iou: 0.621 - ETA: 20s - loss: 0.1124 - mean_iou: 0.621 - ETA: 20s - loss: 0.1119 - mean_iou: 0.621 - ETA: 19s - loss: 0.1109 - mean_iou: 0.621 - ETA: 19s - loss: 0.1102 - mean_iou: 0.621 - ETA: 18s - loss: 0.1086 - mean_iou: 0.622 - ETA: 17s - loss: 0.1090 - mean_iou: 0.622 - ETA: 17s - loss: 0.1093 - mean_iou: 0.622 - ETA: 16s - loss: 0.1085 - mean_iou: 0.622 - ETA: 15s - loss: 0.1076 - mean_iou: 0.622 - ETA: 14s - loss: 0.1077 - mean_iou: 0.623 - ETA: 14s - loss: 0.1073 - mean_iou: 0.623 - ETA: 13s - loss: 0.1076 - mean_iou: 0.623 - ETA: 12s - loss: 0.1075 - mean_iou: 0.623 - ETA: 12s - loss: 0.1079 - mean_iou: 0.623 - ETA: 11s - loss: 0.1088 - mean_iou: 0.624 - ETA: 10s - loss: 0.1094 - mean_iou: 0.624 - ETA: 10s - loss: 0.1092 - mean_iou: 0.624 - ETA: 9s - loss: 0.1089 - mean_iou: 0.624 - ETA: 8s - loss: 0.1101 - mean_iou: 0.62 - ETA: 7s - loss: 0.1106 - mean_iou: 0.62 - ETA: 7s - loss: 0.1107 - mean_iou: 0.62 - ETA: 6s - loss: 0.1106 - mean_iou: 0.62 - ETA: 5s - loss: 0.1101 - mean_iou: 0.62 - ETA: 5s - loss: 0.1102 - mean_iou: 0.62 - ETA: 4s - loss: 0.1102 - mean_iou: 0.62 - ETA: 3s - loss: 0.1100 - mean_iou: 0.62 - ETA: 2s - loss: 0.1102 - mean_iou: 0.62 - ETA: 2s - loss: 0.1105 - mean_iou: 0.62 - ETA: 1s - loss: 0.1106 - mean_iou: 0.62 - ETA: 0s - loss: 0.1107 - mean_iou: 0.62 - ETA: 0s - loss: 0.1110 - mean_iou: 0.6269\n",
      "Epoch 00006: val_loss improved from 0.11425 to 0.10373, saving model to model-dsbowl2018-1.h5\n",
      "603/603 [==============================] - 54s 89ms/step - loss: 0.1109 - mean_iou: 0.6269 - val_loss: 0.1037 - val_mean_iou: 0.6416\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/603 [============================>.] - ETA: 44s - loss: 0.1150 - mean_iou: 0.643 - ETA: 52s - loss: 0.1134 - mean_iou: 0.643 - ETA: 53s - loss: 0.1138 - mean_iou: 0.643 - ETA: 54s - loss: 0.1100 - mean_iou: 0.643 - ETA: 51s - loss: 0.1073 - mean_iou: 0.643 - ETA: 48s - loss: 0.1069 - mean_iou: 0.643 - ETA: 47s - loss: 0.1026 - mean_iou: 0.644 - ETA: 46s - loss: 0.1045 - mean_iou: 0.644 - ETA: 45s - loss: 0.1162 - mean_iou: 0.644 - ETA: 43s - loss: 0.1136 - mean_iou: 0.644 - ETA: 43s - loss: 0.1128 - mean_iou: 0.644 - ETA: 42s - loss: 0.1125 - mean_iou: 0.644 - ETA: 42s - loss: 0.1094 - mean_iou: 0.645 - ETA: 41s - loss: 0.1071 - mean_iou: 0.645 - ETA: 40s - loss: 0.1062 - mean_iou: 0.645 - ETA: 39s - loss: 0.1057 - mean_iou: 0.645 - ETA: 38s - loss: 0.1069 - mean_iou: 0.645 - ETA: 38s - loss: 0.1043 - mean_iou: 0.645 - ETA: 37s - loss: 0.1052 - mean_iou: 0.646 - ETA: 37s - loss: 0.1042 - mean_iou: 0.646 - ETA: 36s - loss: 0.1057 - mean_iou: 0.646 - ETA: 35s - loss: 0.1047 - mean_iou: 0.646 - ETA: 34s - loss: 0.1038 - mean_iou: 0.646 - ETA: 33s - loss: 0.1027 - mean_iou: 0.647 - ETA: 33s - loss: 0.1023 - mean_iou: 0.647 - ETA: 32s - loss: 0.1012 - mean_iou: 0.647 - ETA: 31s - loss: 0.1048 - mean_iou: 0.647 - ETA: 31s - loss: 0.1031 - mean_iou: 0.647 - ETA: 30s - loss: 0.1020 - mean_iou: 0.647 - ETA: 30s - loss: 0.1012 - mean_iou: 0.648 - ETA: 29s - loss: 0.1031 - mean_iou: 0.648 - ETA: 29s - loss: 0.1034 - mean_iou: 0.648 - ETA: 28s - loss: 0.1047 - mean_iou: 0.648 - ETA: 27s - loss: 0.1040 - mean_iou: 0.648 - ETA: 27s - loss: 0.1045 - mean_iou: 0.648 - ETA: 26s - loss: 0.1041 - mean_iou: 0.649 - ETA: 25s - loss: 0.1032 - mean_iou: 0.649 - ETA: 25s - loss: 0.1027 - mean_iou: 0.649 - ETA: 24s - loss: 0.1029 - mean_iou: 0.649 - ETA: 23s - loss: 0.1022 - mean_iou: 0.649 - ETA: 22s - loss: 0.1021 - mean_iou: 0.649 - ETA: 21s - loss: 0.1014 - mean_iou: 0.649 - ETA: 21s - loss: 0.1011 - mean_iou: 0.650 - ETA: 20s - loss: 0.0995 - mean_iou: 0.650 - ETA: 19s - loss: 0.1001 - mean_iou: 0.650 - ETA: 19s - loss: 0.1024 - mean_iou: 0.650 - ETA: 18s - loss: 0.1034 - mean_iou: 0.650 - ETA: 17s - loss: 0.1034 - mean_iou: 0.650 - ETA: 16s - loss: 0.1022 - mean_iou: 0.650 - ETA: 16s - loss: 0.1020 - mean_iou: 0.651 - ETA: 15s - loss: 0.1013 - mean_iou: 0.651 - ETA: 14s - loss: 0.1013 - mean_iou: 0.651 - ETA: 14s - loss: 0.1015 - mean_iou: 0.651 - ETA: 13s - loss: 0.1033 - mean_iou: 0.651 - ETA: 13s - loss: 0.1029 - mean_iou: 0.651 - ETA: 12s - loss: 0.1021 - mean_iou: 0.652 - ETA: 11s - loss: 0.1025 - mean_iou: 0.652 - ETA: 11s - loss: 0.1022 - mean_iou: 0.652 - ETA: 10s - loss: 0.1021 - mean_iou: 0.652 - ETA: 9s - loss: 0.1020 - mean_iou: 0.652 - ETA: 9s - loss: 0.1012 - mean_iou: 0.65 - ETA: 8s - loss: 0.1008 - mean_iou: 0.65 - ETA: 8s - loss: 0.1006 - mean_iou: 0.65 - ETA: 7s - loss: 0.1009 - mean_iou: 0.65 - ETA: 6s - loss: 0.1006 - mean_iou: 0.65 - ETA: 6s - loss: 0.1006 - mean_iou: 0.65 - ETA: 5s - loss: 0.1005 - mean_iou: 0.65 - ETA: 4s - loss: 0.1001 - mean_iou: 0.65 - ETA: 4s - loss: 0.1002 - mean_iou: 0.65 - ETA: 3s - loss: 0.1005 - mean_iou: 0.65 - ETA: 2s - loss: 0.1003 - mean_iou: 0.65 - ETA: 2s - loss: 0.0999 - mean_iou: 0.65 - ETA: 1s - loss: 0.0996 - mean_iou: 0.65 - ETA: 0s - loss: 0.0995 - mean_iou: 0.65 - ETA: 0s - loss: 0.0991 - mean_iou: 0.6547\n",
      "Epoch 00007: val_loss did not improve\n",
      "603/603 [==============================] - 50s 83ms/step - loss: 0.0990 - mean_iou: 0.6547 - val_loss: 0.1058 - val_mean_iou: 0.6662\n",
      "Epoch 8/100\n",
      "600/603 [============================>.] - ETA: 40s - loss: 0.1044 - mean_iou: 0.667 - ETA: 44s - loss: 0.1456 - mean_iou: 0.667 - ETA: 43s - loss: 0.1229 - mean_iou: 0.667 - ETA: 42s - loss: 0.1067 - mean_iou: 0.667 - ETA: 40s - loss: 0.1147 - mean_iou: 0.667 - ETA: 40s - loss: 0.1204 - mean_iou: 0.667 - ETA: 39s - loss: 0.1175 - mean_iou: 0.667 - ETA: 39s - loss: 0.1136 - mean_iou: 0.667 - ETA: 38s - loss: 0.1125 - mean_iou: 0.667 - ETA: 38s - loss: 0.1096 - mean_iou: 0.668 - ETA: 38s - loss: 0.1058 - mean_iou: 0.668 - ETA: 38s - loss: 0.1027 - mean_iou: 0.668 - ETA: 37s - loss: 0.1005 - mean_iou: 0.668 - ETA: 37s - loss: 0.0996 - mean_iou: 0.668 - ETA: 36s - loss: 0.1001 - mean_iou: 0.668 - ETA: 36s - loss: 0.1015 - mean_iou: 0.668 - ETA: 36s - loss: 0.0984 - mean_iou: 0.668 - ETA: 35s - loss: 0.0996 - mean_iou: 0.669 - ETA: 35s - loss: 0.0973 - mean_iou: 0.669 - ETA: 34s - loss: 0.0959 - mean_iou: 0.669 - ETA: 33s - loss: 0.0977 - mean_iou: 0.669 - ETA: 33s - loss: 0.0964 - mean_iou: 0.669 - ETA: 32s - loss: 0.0980 - mean_iou: 0.669 - ETA: 32s - loss: 0.0965 - mean_iou: 0.669 - ETA: 31s - loss: 0.0955 - mean_iou: 0.669 - ETA: 31s - loss: 0.0954 - mean_iou: 0.670 - ETA: 30s - loss: 0.0964 - mean_iou: 0.670 - ETA: 29s - loss: 0.0973 - mean_iou: 0.670 - ETA: 29s - loss: 0.0995 - mean_iou: 0.670 - ETA: 28s - loss: 0.1000 - mean_iou: 0.670 - ETA: 27s - loss: 0.0999 - mean_iou: 0.670 - ETA: 27s - loss: 0.0998 - mean_iou: 0.670 - ETA: 26s - loss: 0.0992 - mean_iou: 0.670 - ETA: 25s - loss: 0.0992 - mean_iou: 0.671 - ETA: 25s - loss: 0.0992 - mean_iou: 0.671 - ETA: 24s - loss: 0.0980 - mean_iou: 0.671 - ETA: 23s - loss: 0.0987 - mean_iou: 0.671 - ETA: 23s - loss: 0.0977 - mean_iou: 0.671 - ETA: 22s - loss: 0.0976 - mean_iou: 0.671 - ETA: 21s - loss: 0.0970 - mean_iou: 0.671 - ETA: 21s - loss: 0.0995 - mean_iou: 0.671 - ETA: 20s - loss: 0.0995 - mean_iou: 0.672 - ETA: 19s - loss: 0.0995 - mean_iou: 0.672 - ETA: 19s - loss: 0.0999 - mean_iou: 0.672 - ETA: 18s - loss: 0.0991 - mean_iou: 0.672 - ETA: 17s - loss: 0.0983 - mean_iou: 0.672 - ETA: 17s - loss: 0.0995 - mean_iou: 0.672 - ETA: 16s - loss: 0.0997 - mean_iou: 0.672 - ETA: 16s - loss: 0.1000 - mean_iou: 0.672 - ETA: 15s - loss: 0.0993 - mean_iou: 0.673 - ETA: 14s - loss: 0.0983 - mean_iou: 0.673 - ETA: 14s - loss: 0.0978 - mean_iou: 0.673 - ETA: 13s - loss: 0.0981 - mean_iou: 0.673 - ETA: 13s - loss: 0.0981 - mean_iou: 0.673 - ETA: 12s - loss: 0.0969 - mean_iou: 0.673 - ETA: 11s - loss: 0.0961 - mean_iou: 0.673 - ETA: 11s - loss: 0.0958 - mean_iou: 0.673 - ETA: 10s - loss: 0.0952 - mean_iou: 0.673 - ETA: 9s - loss: 0.0965 - mean_iou: 0.674 - ETA: 9s - loss: 0.0970 - mean_iou: 0.67 - ETA: 8s - loss: 0.0970 - mean_iou: 0.67 - ETA: 8s - loss: 0.0963 - mean_iou: 0.67 - ETA: 7s - loss: 0.0970 - mean_iou: 0.67 - ETA: 6s - loss: 0.0964 - mean_iou: 0.67 - ETA: 6s - loss: 0.0978 - mean_iou: 0.67 - ETA: 5s - loss: 0.0976 - mean_iou: 0.67 - ETA: 5s - loss: 0.0972 - mean_iou: 0.67 - ETA: 4s - loss: 0.0969 - mean_iou: 0.67 - ETA: 3s - loss: 0.0962 - mean_iou: 0.67 - ETA: 3s - loss: 0.0961 - mean_iou: 0.67 - ETA: 2s - loss: 0.0958 - mean_iou: 0.67 - ETA: 2s - loss: 0.0950 - mean_iou: 0.67 - ETA: 1s - loss: 0.0950 - mean_iou: 0.67 - ETA: 0s - loss: 0.0953 - mean_iou: 0.67 - ETA: 0s - loss: 0.0955 - mean_iou: 0.6759\n",
      "Epoch 00008: val_loss improved from 0.10373 to 0.09552, saving model to model-dsbowl2018-1.h5\n",
      "603/603 [==============================] - 49s 81ms/step - loss: 0.0953 - mean_iou: 0.6760 - val_loss: 0.0955 - val_mean_iou: 0.6853\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376/603 [=================>............] - ETA: 53s - loss: 0.0509 - mean_iou: 0.686 - ETA: 46s - loss: 0.0591 - mean_iou: 0.686 - ETA: 44s - loss: 0.0711 - mean_iou: 0.686 - ETA: 43s - loss: 0.0950 - mean_iou: 0.686 - ETA: 42s - loss: 0.0972 - mean_iou: 0.686 - ETA: 40s - loss: 0.0975 - mean_iou: 0.686 - ETA: 41s - loss: 0.1090 - mean_iou: 0.686 - ETA: 40s - loss: 0.1105 - mean_iou: 0.686 - ETA: 39s - loss: 0.1122 - mean_iou: 0.686 - ETA: 39s - loss: 0.1117 - mean_iou: 0.686 - ETA: 39s - loss: 0.1076 - mean_iou: 0.686 - ETA: 39s - loss: 0.1056 - mean_iou: 0.687 - ETA: 38s - loss: 0.1047 - mean_iou: 0.687 - ETA: 37s - loss: 0.1044 - mean_iou: 0.687 - ETA: 37s - loss: 0.1040 - mean_iou: 0.687 - ETA: 36s - loss: 0.1065 - mean_iou: 0.687 - ETA: 36s - loss: 0.1038 - mean_iou: 0.687 - ETA: 36s - loss: 0.1013 - mean_iou: 0.687 - ETA: 36s - loss: 0.1036 - mean_iou: 0.687 - ETA: 36s - loss: 0.1022 - mean_iou: 0.687 - ETA: 35s - loss: 0.1024 - mean_iou: 0.687 - ETA: 34s - loss: 0.1034 - mean_iou: 0.687 - ETA: 34s - loss: 0.1036 - mean_iou: 0.688 - ETA: 33s - loss: 0.1035 - mean_iou: 0.688 - ETA: 32s - loss: 0.1036 - mean_iou: 0.688 - ETA: 32s - loss: 0.1008 - mean_iou: 0.688 - ETA: 31s - loss: 0.0991 - mean_iou: 0.688 - ETA: 31s - loss: 0.1002 - mean_iou: 0.688 - ETA: 30s - loss: 0.1010 - mean_iou: 0.688 - ETA: 29s - loss: 0.1003 - mean_iou: 0.688 - ETA: 28s - loss: 0.1014 - mean_iou: 0.688 - ETA: 28s - loss: 0.1032 - mean_iou: 0.688 - ETA: 27s - loss: 0.1027 - mean_iou: 0.689 - ETA: 26s - loss: 0.1021 - mean_iou: 0.689 - ETA: 26s - loss: 0.1008 - mean_iou: 0.689 - ETA: 25s - loss: 0.1009 - mean_iou: 0.689 - ETA: 24s - loss: 0.0995 - mean_iou: 0.689 - ETA: 23s - loss: 0.0984 - mean_iou: 0.689 - ETA: 23s - loss: 0.0980 - mean_iou: 0.689 - ETA: 22s - loss: 0.0964 - mean_iou: 0.689 - ETA: 21s - loss: 0.0954 - mean_iou: 0.689 - ETA: 21s - loss: 0.0963 - mean_iou: 0.689 - ETA: 20s - loss: 0.0947 - mean_iou: 0.689 - ETA: 19s - loss: 0.0951 - mean_iou: 0.690 - ETA: 19s - loss: 0.0945 - mean_iou: 0.690 - ETA: 18s - loss: 0.0942 - mean_iou: 0.690 - ETA: 17s - loss: 0.0951 - mean_iou: 0.6903"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d9eb5562d482>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m results = model.fit(X_train, Y_train, validation_split=val_split, batch_size=8, epochs=n_epochs, \n\u001b[1;32m---> 11\u001b[1;33m                     callbacks=[earlystopper, checkpointer])\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1669\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1206\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1207\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2475\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2476\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
    "checkpointer = ModelCheckpoint('model-dsbowl2018-1.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "# setup\n",
    "n_epochs  = 100\n",
    "val_split = 0.10\n",
    "\n",
    "# fitting\n",
    "results = model.fit(X_train, Y_train, validation_split=val_split, batch_size=8, epochs=n_epochs, \n",
    "                    callbacks=[earlystopper, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict on train, val and test\n",
    "model = load_model('model-dsbowl2018-1.h5', custom_objects={'mean_iou': mean_iou})\n",
    "preds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\n",
    "preds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\n",
    "preds_test = model.predict(X_test, verbose=1)\n",
    "\n",
    "# Threshold predictions\n",
    "thr = 0.50\n",
    "preds_train_t = (preds_train > thr).astype(np.uint8)\n",
    "preds_val_t = (preds_val > thr).astype(np.uint8)\n",
    "preds_test_t = (preds_test > thr).astype(np.uint8)\n",
    "\n",
    "# Create list of upsampled test masks\n",
    "preds_test_upsampled = []\n",
    "for i in range(len(preds_test)):\n",
    "    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n",
    "                                       (sizes_test[i][0], sizes_test[i][1]), \n",
    "                                       mode='constant', preserve_range=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform a sanity check on some random training samples\n",
    "ix = random.randint(0, len(preds_train_t))\n",
    "imshow(X_train[ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(preds_train_t[ix]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform a sanity check on some random validation samples\n",
    "ix = random.randint(0, len(preds_val_t))\n",
    "imshow(X_train[int(X_train.shape[0]*0.9):][ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[int(Y_train.shape[0]*0.9):][ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(preds_val_t[ix]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run-length encoding \n",
    "def rle_encoding(x):\n",
    "    dots = np.where(x.T.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "def prob_to_rles(x, cutoff=0.5):\n",
    "    lab_img = label(x > cutoff)\n",
    "    for i in range(1, lab_img.max() + 1):\n",
    "        yield rle_encoding(lab_img == i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_test_ids = []\n",
    "rles = []\n",
    "for n, id_ in enumerate(test_ids):\n",
    "    rle = list(prob_to_rles(preds_test_upsampled[n]))\n",
    "    rles.extend(rle)\n",
    "    new_test_ids.extend([id_] * len(rle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create submission DataFrame\n",
    "sub = pd.DataFrame()\n",
    "sub['ImageId'] = new_test_ids\n",
    "sub['EncodedPixels'] = pd.Series(rles).apply(lambda x: ' '.join(str(y) for y in x))\n",
    "\n",
    "fname ='sub-dsbowl nep '+str(n_epochs)+' vsplit '+str(val_split)+' seed '+str(seed)+' thr'+str(thr)+'.csv'\n",
    "\n",
    "sub.to_csv(fname, index=False)\n",
    "\n",
    "nm=(time.time() - start_time)/60\n",
    "print (\"Total time %s min\" % nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
